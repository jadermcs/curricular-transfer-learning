{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"models/gpt2/ta_encode/multiwoz\",\n",
    "                                            padding_side=\"left\", truncation_side=\"left\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"models/gpt2/ta_encode/multiwoz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ff1588b4a0715cd\n",
      "Reusing dataset json (/home/jader/.cache/huggingface/datasets/json/default-9ff1588b4a0715cd/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040d1f39e9c84a7b8fc611b236f6b367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"json\", data_files={\n",
    "        \"train\": \"data/multiwoz/train/encoded.json\",\n",
    "        \"valid\": \"data/multiwoz/dev/encoded.json\",\n",
    "        \"test\": \"data/multiwoz/test/encoded.json\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select * from train where  departure='broxbourne' and destination='cambridge' and leaveat > '10:15'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('TR9199',\n",
       " '11:32',\n",
       " 'monday',\n",
       " 'broxbourne',\n",
       " 'cambridge',\n",
       " '60 minutes',\n",
       " '10:32',\n",
       " '17.90 pounds')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import dbPointer\n",
    "dbPointer.queryResultVenues(\"train\", {\n",
    "                        \"departure\" :\"broxbourne\",\n",
    "                        \"destination\": \"cambridge\",\n",
    "                        \"leaveat\": \"10:15\"\n",
    "                        }, True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:01:49<00:00,  7.31s/it]     \n"
     ]
    }
   ],
   "source": [
    "sizencode = 256\n",
    "predicted = {}\n",
    "for batch in tqdm(datasets[\"test\"]):\n",
    "    did = batch[\"id\"].lower().rstrip(\".json\")\n",
    "    utterances = batch[\"text\"].split(\"<sos_r>\")\n",
    "    predicted[did] = []\n",
    "    responses = []\n",
    "    for i in range(len(utterances)-1):\n",
    "        example = \"<sos_r>\".join(utterances[:i+1])[-sizencode:]\n",
    "        responses.append(example)\n",
    "    encode = tokenizer(responses, return_tensors=\"pt\", truncation=True,\n",
    "                        padding=True, max_length=sizencode)\n",
    "    gen = model.generate(\n",
    "        **encode,\n",
    "        max_new_tokens=80,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.encode(\"<eos_r>\")[0]\n",
    "    )\n",
    "    for response in gen:\n",
    "        response = tokenizer.decode(response)\n",
    "        predicted[did].append({\n",
    "            \"response\": response.split(\"<sos_r>\")[-1].split(\"<eos_r>\")[0].strip(),\n",
    "            # TODO\n",
    "            # \"state\": response.split(\"<sos_b>\")[-1].split(\"<eos_b>\")[0].strip(),\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': {'mwz22': 14.149226756890032}, 'success': None, 'richness': {'entropy': 6.044637005567655, 'cond_entropy': 1.9912459899261963, 'avg_lengths': 18.25881714595768, 'msttr': 0.6195839524517073, 'num_unigrams': 492, 'num_bigrams': 2244, 'num_trigrams': 4541}, 'dst': None}\n"
     ]
    }
   ],
   "source": [
    "from mwzeval.metrics import Evaluator\n",
    "e = Evaluator(bleu=True, success=False, richness=True)\n",
    "results = e.evaluate(predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co/' to load this model and it looks like models/gpt2/multiwoz is not the path to a directory conaining a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/curricular-transfer-learning/venv/lib/python3.8/site-packages/transformers/configuration_utils.py:594\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    593\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m    595\u001b[0m         config_file,\n\u001b[1;32m    596\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    597\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    598\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    599\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    600\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    601\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    602\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    603\u001b[0m     )\n\u001b[1;32m    605\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/curricular-transfer-learning/venv/lib/python3.8/site-packages/transformers/file_utils.py:1921\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m   1920\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m-> 1921\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m   1922\u001b[0m         url_or_filename,\n\u001b[1;32m   1923\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1924\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1925\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1926\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1927\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1928\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1929\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1930\u001b[0m     )\n\u001b[1;32m   1931\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m   1932\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[0;32m~/curricular-transfer-learning/venv/lib/python3.8/site-packages/transformers/file_utils.py:2125\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   2124\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mhead(url, headers\u001b[39m=\u001b[39mheaders, allow_redirects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, proxies\u001b[39m=\u001b[39mproxies, timeout\u001b[39m=\u001b[39metag_timeout)\n\u001b[0;32m-> 2125\u001b[0m _raise_for_status(r)\n\u001b[1;32m   2126\u001b[0m etag \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Linked-Etag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/curricular-transfer-learning/venv/lib/python3.8/site-packages/transformers/file_utils.py:2052\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         \u001b[39mraise\u001b[39;00m RevisionNotFoundError((\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m404 Client Error: Revision Not Found for url: \u001b[39m\u001b[39m{\u001b[39;00mrequest\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 2052\u001b[0m request\u001b[39m.\u001b[39;49mraise_for_status()\n",
      "File \u001b[0;32m~/curricular-transfer-learning/venv/lib/python3.8/site-packages/requests/models.py:960\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m--> 960\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/models/gpt2/multiwoz/resolve/main/config.json",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/jader/curricular-transfer-learning/eval.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jader/curricular-transfer-learning/eval.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m GPT2LMHeadModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mmodels/gpt2/multiwoz\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/curricular-transfer-learning/venv/lib/python3.8/site-packages/transformers/modeling_utils.py:1278\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   1277\u001b[0m     config_path \u001b[39m=\u001b[39m config \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 1278\u001b[0m     config, model_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m   1279\u001b[0m         config_path,\n\u001b[1;32m   1280\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1281\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1282\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1283\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1284\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1285\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1286\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1287\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1288\u001b[0m         _from_auto\u001b[39m=\u001b[39;49mfrom_auto_class,\n\u001b[1;32m   1289\u001b[0m         _from_pipeline\u001b[39m=\u001b[39;49mfrom_pipeline,\n\u001b[1;32m   1290\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1291\u001b[0m     )\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     model_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/curricular-transfer-learning/venv/lib/python3.8/site-packages/transformers/configuration_utils.py:519\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPretrainedConfig\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    447\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[39m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[39m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    520\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type:\n\u001b[1;32m    521\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    522\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are using a model of type \u001b[39m\u001b[39m{\u001b[39;00mconfig_dict[\u001b[39m'\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m to instantiate a model of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    523\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m         )\n",
      "File \u001b[0;32m~/curricular-transfer-learning/venv/lib/python3.8/site-packages/transformers/configuration_utils.py:546\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    545\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    548\u001b[0m \u001b[39m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfiguration_files\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n",
      "File \u001b[0;32m~/curricular-transfer-learning/venv/lib/python3.8/site-packages/transformers/configuration_utils.py:623\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    620\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m does not appear to have a file named \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    621\u001b[0m     )\n\u001b[1;32m    622\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError:\n\u001b[0;32m--> 623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    624\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to load this model and it looks like \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    625\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a directory conaining a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    626\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfile.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to run the library in offline mode at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    627\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    628\u001b[0m     )\n\u001b[1;32m    629\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load config for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    634\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    635\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co/' to load this model and it looks like models/gpt2/multiwoz is not the path to a directory conaining a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"models/gpt2/multiwoz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizencode = 256\n",
    "predicted = {}\n",
    "for batch in tqdm(datasets[\"test\"]):\n",
    "    did = batch[\"id\"].lower().rstrip(\".json\")\n",
    "    utterances = batch[\"text\"].split(\"<sos_r>\")\n",
    "    predicted[did] = []\n",
    "    responses = []\n",
    "    for i in range(len(utterances)-1):\n",
    "        example = \"<sos_r>\".join(utterances[:i+1])[-sizencode:]\n",
    "        responses.append(example)\n",
    "    encode = tokenizer(responses, return_tensors=\"pt\", truncation=True,\n",
    "                        padding=True, max_length=sizencode)\n",
    "    gen = model2.generate(\n",
    "        **encode,\n",
    "        max_new_tokens=80,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.encode(\"<eos_r>\")[0]\n",
    "    )\n",
    "    for response in gen:\n",
    "        response = tokenizer.decode(response)\n",
    "        predicted[did].append({\n",
    "            \"response\": response.split(\"<sos_r>\")[-1].split(\"<eos_r>\")[0].strip(),\n",
    "            # TODO\n",
    "            # \"state\": response.split(\"<sos_b>\")[-1].split(\"<eos_b>\")[0].strip(),\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mwzeval.metrics import Evaluator\n",
    "e = Evaluator(bleu=True, success=False, richness=True)\n",
    "results = e.evaluate(predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos_u> I need a train going to Cambridge that will depart after 10:15 from broxbourne. <eos_u><sos_b>[find_train]train-departure broxbourne train-destination cambridge train-leaveat 10:15<eos_b><sos_a>[train-inform] choice many [train-request] day?<eos_a><sos_r>There are <value_choice> trains that meet your criteria. What day would you like to travel?<eos_r><sos_u>I would like to leave on Tuesday.<eos_u><sos_b>[find_train]train-day t\n"
     ]
    }
   ],
   "source": [
    "text = \"<sos_u> I need a train going to Cambridge that will depart after 10:15 from broxbourne. <eos_u>\"\n",
    "for i in range(80):\n",
    "    example = tokenizer(text, return_tensors=\"pt\")\n",
    "    logits = model(**example).logits[0]\n",
    "    text += tokenizer.decode(torch.argmax(logits[-1]))\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d443db0b2d7070e98e0d2867c7b006d8f03401788aa1751aefd698da472da378"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
